import pytest
import os
import uuid
import json
import pymupdf
from pathlib import Path
from ingest.hybrid_ingestor import HybridIngestor
from ingest.models import ContentAtom, StructureNode
from ingest.schemas import LanguageMetadata, STEMMetadata, HistoryMetadata

# This file will be generated by the test
OUTPUT_FILE = Path(__file__).parent / "integration_rag.py"
BIG_DATA_FILE = Path("data/toy_green_line_1.pdf")
DATA_FILE = Path("data/toy_green_line_small.pdf")

def ensure_small_pdf():
    """Creates a smaller version of the PDF for testing if it doesn't exist."""
    if DATA_FILE.exists():
        return

    if not BIG_DATA_FILE.exists():
        pytest.skip(f"Big data file {BIG_DATA_FILE} not found, cannot create small PDF.")

    print(f"Creating small PDF from {BIG_DATA_FILE}...")
    try:
        doc = pymupdf.open(BIG_DATA_FILE)
        new_doc = pymupdf.open()
        # Take first 5 pages
        to_page = min(5, len(doc))
        new_doc.insert_pdf(doc, from_page=0, to_page=to_page-1)
        new_doc.save(DATA_FILE)
        print(f"Created {DATA_FILE}")
    except Exception as e:
        pytest.skip(f"Failed to create small PDF: {e}")

def serialize_data(nodes, atoms):
    """
    Serializes nodes and atoms into a python file string.
    """
    # Helper to clean up string representation
    def clean_repr(obj):
        # We need to construct the imports for these objects to work
        return repr(obj)

    # We need to handle Pydantic models.
    # repr(atom) might show `ContentAtom(id=..., ...)` which is good if we import ContentAtom.
    # But for metadata fields which are Pydantic models, repr() works too.

    # Let's verify imports in the generated file
    lines = [
        "import uuid",
        "from uuid import UUID",
        "from ingest.models import ContentAtom, StructureNode",
        "from ingest.schemas import LanguageMetadata, STEMMetadata, HistoryMetadata",
        "",
        "# Generated Integration Data",
        f"DATA_NODES = {repr(nodes)}",
        "",
        f"DATA_ATOMS = {repr(atoms)}"
    ]
    return "\n".join(lines)

@pytest.fixture
def ingestor():
    return HybridIngestor()

def test_docling_ingestion_and_generation(ingestor):
    """
    Tests the default Docling ingestion path and generates the integration data file.
    """
    print("Test started. Verifying data file...")
    ensure_small_pdf()
    if not DATA_FILE.exists():
        pytest.skip(f"Data file {DATA_FILE} not found")

    book_id = uuid.uuid4()
    print(f"\nRunning Docling Ingestion on {DATA_FILE}...")

    # Docling is synchronous in hybrid_ingestor
    nodes, atoms = ingestor.ingest_book(str(DATA_FILE), book_id)

    assert len(nodes) > 0, "Docling failed to extract nodes"
    assert len(atoms) > 0, "Docling failed to extract atoms"

    print(f"Extracted {len(nodes)} nodes and {len(atoms)} atoms.")

    # Generate the file
    content = serialize_data(nodes, atoms)
    with open(OUTPUT_FILE, "w") as f:
        f.write(content)

    print(f"Generated integration data at {OUTPUT_FILE}")

def test_openai_ingestion(ingestor):
    """
    Tests the OpenAI VLM ingestion path.
    """
    if not os.getenv("OPENAI_API_KEY"):
        pytest.skip("OPENAI_API_KEY not set")

    if not DATA_FILE.exists():
        pytest.skip(f"Data file {DATA_FILE} not found")

    book_id = uuid.uuid4()
    print(f"\nRunning OpenAI Ingestion on {DATA_FILE}...")

    # OpenAI ingestion is usually handled via hybrid fallback or explicit call.
    # ingest_with_openai calls async code synchronously via asyncio.run inside the method?
    # Let's check hybrid_ingestor.py again.
    # Yes: `pages_data = asyncio.run(self.openai_ingestor.ingest_book(file_path, category=category))`
    # Since we are already in an async test (pytest-asyncio), calling `asyncio.run` again might cause issues
    # if the loop is running.
    # hybrid_ingestor.ingest_with_openai is NOT async defined, but it calls asyncio.run.
    # This might fail "RuntimeError: asyncio.run() cannot be called from a running event loop".

    # To fix this, we should check if we can call the internal async method or if we need to run this test synchronously.
    # `HybridIngestor.ingest_with_openai` is a sync wrapper.

    try:
        nodes, atoms = ingestor.ingest_with_openai(str(DATA_FILE), book_id, category="language")
    except RuntimeError as e:
        if "asyncio.run() cannot be called from a running event loop" in str(e):
            # We are in an async test, so we should call the underlying async method if possible,
            # OR make this test synchronous.
            # But the fixture 'ingestor' is just a class.
            # Let's try running this test as a standard sync test first.
            raise e
        else:
            raise e

    assert len(nodes) > 0
    assert len(atoms) > 0
    print(f"OpenAI Extracted {len(nodes)} nodes and {len(atoms)} atoms.")
